{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "IdZPni5bPp7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.constant(np.array([[0., 0., 1., 1.],\n",
        "                          [0., 1., 0., 1.]]))\n",
        "X = np.vstack((np.ones((1, x.shape[1])), x))\n",
        "t = tf.constant(np.array([0., 0., 0., 1.]))\n",
        "\n",
        "W_0 = tf.Variable(np.zeros((1, 3)))"
      ],
      "metadata": {
        "id": "2d-vUK60PoTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1\n",
        "MAX_EPOCHS = 400\n",
        "\n",
        "weight_updates = []\n",
        "E_list = []\n",
        "min_error = float('inf')  # Initialize with positive infinity\n",
        "min_W_0 = None  # Initialize with None\n"
      ],
      "metadata": {
        "id": "GqVAAQzSPl9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "He52CuZLPLqf"
      },
      "outputs": [],
      "source": [
        "for ep in range(MAX_EPOCHS):\n",
        "    for inp, out in zip(X.T, t):\n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "            tape.watch(W_0)\n",
        "\n",
        "            # Forward pass\n",
        "            # Layer 1\n",
        "            Z_1 = W_0 @ inp.reshape(-1, 1)\n",
        "            A_1 = tf.keras.activations.sigmoid(Z_1)\n",
        "\n",
        "            # Calculate error\n",
        "            E = 0.5 * tf.reduce_mean(tf.square(A_1 - out))\n",
        "            E_list.append(E.numpy())\n",
        "\n",
        "        # Check if current error is the minimum\n",
        "        if E < min_error:\n",
        "            min_error = E\n",
        "            min_W_0 = W_0.numpy().copy()\n",
        "\n",
        "        # Backward pass for output layer\n",
        "        dE_dW0 = tape.gradient(E, W_0)\n",
        "\n",
        "        # Update weights for output layer\n",
        "        W_0.assign_sub(lr * dE_dW0)\n",
        "\n",
        "        weight_updates.append(W_0.numpy().copy())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Minimum error:\", min_error.numpy())\n",
        "print(\"Corresponding W_0:\", min_W_0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpaaTvflPrmf",
        "outputId": "bc6ca139-1c1d-4baa-861c-087b1ed615b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum error: 7.28550387211331e-07\n",
            "Corresponding W_0: [[-6.7183231   4.42915375  4.4196892 ]]\n"
          ]
        }
      ]
    }
  ]
}